{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COLAB_maDLC2_VideoAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bearbrice/maDLC_MM_hands2_trained/blob/main/COLAB_maDLC2_VideoAnalysis2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK255E7YoEIt"
      },
      "source": [
        "# DeepLabCut 2.2 Toolbox - COLAB\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590444465547-SHXODUII311HEE407IL6/ke17ZwdGBToddI8pDm48kE4VnnB9_j2k1VP236ADqAFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQg9Vf0owGyf3dhfDKy8SxMujaKmp2B54Sb3VS1rO76Whq-cUhHVuKFlGUXsU9tJk/ezgif.com-video-to-gif.gif?format=1500w)\n",
        "\n",
        "https://github.com/DeepLabCut/DeepLabCut\n",
        "\n",
        "This notebook illustrates how to, for multi-animal projects, use the cloud-based GPU to:\n",
        "- create a multi-animal training set\n",
        "- train a network\n",
        "- evaluate a network\n",
        "- cross evaluate inference parameters\n",
        "- analyze novel videos\n",
        "- assemble tracklets\n",
        "- create quality check plots\n",
        "\n",
        "###This notebook assumes you already have a project folder with labeled data! \n",
        "\n",
        "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
        "\n",
        "This shows the most simple code to do so, but many of the functions have additional features, so please check out the docs on GitHub.\n",
        "\n",
        "Mathis et al, in prep. <- please note, we are providing this toolbox as an early access release; more feeatures and details will be released with the forthcoming paper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txoddlM8hLKm"
      },
      "source": [
        "## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q23BzhA6CXxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f63c49-bb33-4e31-bea6-e657be9390c9"
      },
      "source": [
        "#(this will take a few minutes to install all the dependences!)\n",
        "!pip install deeplabcut\n",
        "%reload_ext numpy\n",
        "%reload_ext scipy\n",
        "%reload_ext matplotlib\n",
        "%reload_ext mpl_toolkits"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deeplabcut in /usr/local/lib/python3.7/dist-packages (2.1.10.4)\n",
            "Requirement already satisfied: opencv-python-headless~=3.4.9.33 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.4.9.33)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.4.5)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.8.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.29.23)\n",
            "Requirement already satisfied: numba==0.51.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.51.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (5.5.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (57.2.0)\n",
            "Requirement already satisfied: scikit-image>=0.17 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.18.2)\n",
            "Requirement already satisfied: tensorpack==0.9.8 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.9.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2021.5.30)\n",
            "Requirement already satisfied: ruamel.yaml>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.17.10)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.4.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.13)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.0)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.12.2)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2021.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (7.1.2)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.5.1)\n",
            "Requirement already satisfied: numpy~=1.17.3 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.17.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.15.0)\n",
            "Requirement already satisfied: moviepy<=1.0.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.3.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.1.0)\n",
            "Requirement already satisfied: matplotlib==3.1.3 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.1.3)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.4.1)\n",
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.36.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->deeplabcut) (2018.9)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba==0.51.1->deeplabcut) (0.34.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (5.0.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (4.8.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (2021.7.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (7.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (22.1.0)\n",
            "Requirement already satisfied: msgpack-numpy>=0.4.4.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (0.4.7.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (5.4.8)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (0.8.9)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (1.0.2)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15.0->deeplabcut) (0.2.6)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from tables->deeplabcut) (2.7.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->deeplabcut) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->deeplabcut) (1.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deeplabcut) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->deeplabcut) (1.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->deeplabcut) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->deeplabcut) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->deeplabcut) (1.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->deeplabcut) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->deeplabcut) (0.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTwAcbq2-FZz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fab06471-78e8-44cd-9ca4-2a1735b4e282"
      },
      "source": [
        "# Use TensorFlow 1.x:\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "#GUIs don't work on the cloud, so we supress them:\n",
        "import os\n",
        "os.environ[\"DLClight\"]=\"True\"\n",
        "import deeplabcut\n",
        "deeplabcut.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.10.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-nlTkri4HZ"
      },
      "source": [
        "# GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS4Q4UkR9rgG",
        "outputId": "8df42b69-372a-4d97-8c70-3ab29497fefa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Clone the github repository\n",
        "!git clone -l -s git://github.com/Bearbrice/maDLC_MM_hands2_trained.git\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'maDLC_MM_hands2_trained'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 1534, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1534 (delta 1), reused 5 (delta 1), pack-reused 1529\u001b[K\n",
            "Receiving objects: 100% (1534/1534), 169.49 MiB | 30.77 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "maDLC_MM_hands2_trained  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbCUVh5mmIVS"
      },
      "source": [
        "# Drive google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egyEtu_8mKNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d051585-0ddf-425d-f26d-7cc6b9ca0b0d"
      },
      "source": [
        "#Now, let's link to your GoogleDrive. Run this cell and follow the authorization instructions:\n",
        "#(We recommend putting a copy of the github repo in your google drive if you are using the demo \"examples\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH4G7u1V7jpl"
      },
      "source": [
        "# Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zNQVmR3yFH",
        "outputId": "b1be5ea2-9b6c-4eb9-a93e-efe48adbff41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# !wget https://drive.google.com/file/d/1wrtFDOhth8J7HKuYZ_K1Joaqv2mnjetz/view?usp=sharing\n",
        "\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1wrtFDOhth8J7HKuYZ_K1Joaqv2mnjetz\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wrtFDOhth8J7HKuYZ_K1Joaqv2mnjetz\n",
            "To: /content/maDLC2_AfterTraining.zip\n",
            "1.01GB [00:06, 152MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTmoqlTiB8fP"
      },
      "source": [
        "# Create a ZipFile Object and load sample.zip in it\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/maDLC2_AfterTraining.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frnj1RVDyEqs"
      },
      "source": [
        "## YOU WILL NEED TO EDIT THE PROJECT PATH **in the config.yaml file** TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
        "\n",
        "Now, you can do this within COLAB! Simply navigate in the left panel to your project folder, double click on the config.yaml file, and you will see it load on the right! Edit the first part of your path, to match:\n",
        "\n",
        " /content/drive/My Drive/yourProjectFolderName\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhENAlQnFENJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "642e9933-b3b1-4861-ffc4-55efc55ca50b"
      },
      "source": [
        "# PLEASE EDIT THIS:\n",
        "VideoType = 'mp4' #, mp4, MOV, or avi, whatever you uploaded!\n",
        "\n",
        "shuffle=1\n",
        "\n",
        "# No need to edit this, we are going to assume you put videos you want to analyze in the \"videos\" folder, but if this is NOT true, edit below:\n",
        "videofile_path = ['/content/maDLC_MM_hands2_trained/Inference_videos'] #Enter the list of videos or folder to analyze.\n",
        "videofile_path\n",
        "\n",
        "\n",
        "#No need to edit this, as you set it when you passed the ProjectFolderName (above): \n",
        "path_config_file = '/content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/config.yaml'\n",
        "path_config_file\n",
        "#This creates a path variable that links to your google drive project"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/config.yaml'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFLSKKfoEJk"
      },
      "source": [
        "## Start Analyzing videos: \n",
        "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
        "\n",
        "The results are stored in hd5 file in the same directory where the video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LZiS_0oEJl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32b0217b-ee55-4a6b-8f71-6ecf799b9cbf"
      },
      "source": [
        "print(\"Start Analyzing my video(s)!\")\n",
        "scorername = deeplabcut.analyze_videos(path_config_file, \n",
        "                                       videofile_path, \n",
        "                                       shuffle=shuffle, \n",
        "                                       videotype=VideoType, \n",
        "                                       c_engine=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Analyzing my video(s)!\n",
            "Using snapshot-20000 for model /content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1\n",
            "Initializing ResNet\n",
            "Activating extracting of PAFs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: /content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1/train/snapshot-20000.data-00000-of-00001; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_301]]\n  (1) Not found: /content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1/train/snapshot-20000.data-00000-of-00001; No such file or directory\n\t [[{{node save/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: /content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1/train/snapshot-20000.data-00000-of-00001; No such file or directory\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[save/RestoreV2/_301]]\n  (1) Not found: /content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1/train/snapshot-20000.data-00000-of-00001; No such file or directory\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 451, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 434, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-213d8938cf3d>\", line 6, in <module>\n    c_engine=False)\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/predict_videos.py\", line 271, in analyze_videos\n    sess, inputs, outputs = predict.setup_pose_prediction(dlc_cfg)\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/nnet/predict.py\", line 48, in setup_pose_prediction\n    restorer = TF.train.Saver()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1299\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-213d8938cf3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                        \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                        \u001b[0mvideotype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVideoType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                        c_engine=False)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/predict_videos.py\u001b[0m in \u001b[0;36manalyze_videos\u001b[0;34m(config, videos, videotype, shuffle, trainingsetindex, gputouse, save_as_csv, destfolder, batchsize, cropping, get_nframesfrommetadata, TFGPUinference, dynamic, modelprefix, c_engine, robust_nframes)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_GPUpose_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_pose_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     pdindex = pd.MultiIndex.from_product(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/nnet/predict.py\u001b[0m in \u001b[0;36msetup_pose_prediction\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Restore variables from disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1306\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: /content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1/train/snapshot-20000.data-00000-of-00001; No such file or directory\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[save/RestoreV2/_301]]\n  (1) Not found: /content/maDLC_MM_hands2_trained/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1/train/snapshot-20000.data-00000-of-00001; No such file or directory\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 451, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 434, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-213d8938cf3d>\", line 6, in <module>\n    c_engine=False)\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/predict_videos.py\", line 271, in analyze_videos\n    sess, inputs, outputs = predict.setup_pose_prediction(dlc_cfg)\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/nnet/predict.py\", line 48, in setup_pose_prediction\n    restorer = TF.train.Saver()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxRLS2_-r55K"
      },
      "source": [
        "## The steps below work on a single video at a time.\n",
        "- Here you can create a video to check the pose estimation detection quality! If this looks good, proceed to tracklet conversions with the interactive GUI (ouside of COLAB for now), or if you know your optimal parameters, you can automate this and run the additional steps shown in a few cells down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mWwX5bTc5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2aa5d57-6421-4c9e-c2ac-4da8620a1f93"
      },
      "source": [
        "##### PROTIP: #####\n",
        "## look at the output video; if the pose estimation (i.e. key points)\n",
        "##  don't look good, don't proceed with tracking - add more data to your training set and re-train!\n",
        "\n",
        "#let's check a specific video (PLEASE EDIT VIDEO PATH):\n",
        "Specific_videofile = '/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1.mp4'\n",
        "\n",
        "# from deeplabcut.utils import auxiliaryfunctions\n",
        "# scorername, DLCscorerlegacy = auxiliaryfunctions.GetScorerName(path_config_file, shuffle, trainFraction=0)\n",
        "# print(\"scorename is: \"+scorername)\n",
        "\n",
        "deeplabcut.create_video_with_all_detections(path_config_file, [Specific_videofile], scorername)\n",
        "\n",
        "#Again, if this does not look perfect, do not proceed! Retrain with more diverse data."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/206 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating labeled video for  VPers1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/206 [00:01<00:00, 128.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78x3BbotIsuO"
      },
      "source": [
        "## Convert Detections to Tracklets:\n",
        "\n",
        "- The idea is that you test and adapt hyperparameters for tracking outside of COLAB. Once you have good parameters, this can be automated on future videos. Shown here!\n",
        "\n",
        "- I.e., instead of always doing an interactive parameter setting step, you can simply convert tracklets to .h5 files using these parameters (see GitHub for more info)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIvXM7TXIs-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a10ad9-b54b-4fe9-aeec-d30d0cbd4762"
      },
      "source": [
        "#assemble tracklets:\n",
        "#read the docs: which tracker to test out (you can run this many times to try multiple):\n",
        "tracktype= 'box' #box, skeleton, ellipse\n",
        "\n",
        "deeplabcut.convert_detections2tracklets(path_config_file, Specific_videofile, videotype=VideoType,\n",
        "                                                    shuffle=shuffle, track_method=tracktype, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using snapshot-20000 for model /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/maDLC_MM_hands-Brice-2021-07-08/dlc-models/iteration-0/maDLC_MM_handsJul8-trainset95shuffle1\n",
            "Processing...  /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1.mp4\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos  already exists!\n",
            "Analyzing /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "206it [00:04, 47.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The tracklets were created. Now you can 'refine_tracklets'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHH9lCM7JCZ0"
      },
      "source": [
        "## Now you should manually verify the tracks and correct them if needed! [currently only working outside of COLAB]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocRzxq7fJCjm"
      },
      "source": [
        "''' here is the code you would need:\n",
        "os.environ[\"DLClight\"]=\"False\"\n",
        "import deeplabcut\n",
        "\n",
        "#ATTENTION:\n",
        "picklefile = '/...._10000_bx.pickle' #(see your video folder for path i.e. right click and say copy path!!!)\n",
        "vid ='/yourVIDEO.mp4'\n",
        "#if you want occlusions filled in, tell us how many frames to fill in, i.e. if there is a gap in data:\n",
        "framestofill = 0. #note, put \"0\" if you want ALL gaps filled!\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from deeplabcut import refine_tracklets\n",
        "TrackletManager, TrackletVisualizer = refine_tracklets(path_config_file, \n",
        "                                                          picklefile, \n",
        "                                                          Specific_videofile, \n",
        "                                                          min_swap_frac=0,\n",
        "                                                          min_tracklet_frac=0, \n",
        "                                                          max_gap=framestofill)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUOKrLJRseUX"
      },
      "source": [
        "## Let's assume you have great tracking parameters, and you want to analyze a full set of videos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6izVWX8sdzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cb3dde-6a59-4b20-c73c-c68bc6773e64"
      },
      "source": [
        "#^^^^^^^^^You do NOT neeed to run if you hit \"save\" in the GUI ^^^^^^^^^^\n",
        "#this is just if you want to run the same parameters over a set of videos!\n",
        "\n",
        "# You need to point to your pickle file, please \"copy path\" from the folder to the left (right click, copy path)\n",
        "picklefile = '/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000_bx.pickle' #(see your video folder for path i.e. right click and say copy path!!!)\n",
        "vid ='/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1.mp4'\n",
        "\n",
        "deeplabcut.convert_raw_tracks_to_h5(path_config_file, picklefile)\n",
        "deeplabcut.filterpredictions(path_config_file, \n",
        "                                 videofile_path, \n",
        "                                 videotype=VideoType, \n",
        "                                 track_method = tracktype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 455.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Analyzing all the videos in the directory...\n",
            "Filtering with median model /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot05-2_CUT.mp4\n",
            "No unfiltered data file found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot05-2_CUT and scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000 and box tracker.\n",
            "Filtering with median model /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Video_Pers2_CUT.mp4\n",
            "Data from Video_Pers2_CUT were already filtered. Skipping...\n",
            "Filtering with median model /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot06-2_CUT.mp4\n",
            "Data from Pilot06-2_CUT were already filtered. Skipping...\n",
            "Filtering with median model /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot03-2.mp4\n",
            "No unfiltered data file found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot03-2 and scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000 and box tracker.\n",
            "Filtering with median model /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1.mp4\n",
            "Saving filtered csv poses!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk4xGb8Ftf3B"
      },
      "source": [
        "## Create plots of your trajectories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX21zZbXoEKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45f3166-e366-458d-d3f0-895c5180da45"
      },
      "source": [
        "deeplabcut.plot_trajectories(path_config_file,videofile_path, videotype=VideoType, track_method=tracktype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analyzing all the videos in the directory...\n",
            "Loading  /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Video_Pers2_CUT.mp4 and data.\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/plot-poses/Video_Pers2_CUT  already exists!\n",
            "Loading  /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot06-2_CUT.mp4 and data.\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/plot-poses/Pilot06-2_CUT  already exists!\n",
            "Loading  /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1.mp4 and data.\n",
            "Loading  /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot05-2_CUT.mp4 and data.\n",
            "No unfiltered data file found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot05-2_CUT and scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000 and box tracker.\n",
            "No detection data found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot05-2_CUT, scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000, and tracker box\n",
            "Make sure /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot05-2_CUT.mp4 was previously analyzed, and that detections were successively converted to tracklets using \"deeplabcut.convert_detections2tracklets()\" and \"deeplabcut.convert_raw_tracks_to_h5()\".\n",
            "Loading  /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot03-2.mp4 and data.\n",
            "No unfiltered data file found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot03-2 and scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000 and box tracker.\n",
            "No detection data found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot03-2, scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000, and tracker box\n",
            "Make sure /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot03-2.mp4 was previously analyzed, and that detections were successively converted to tracklets using \"deeplabcut.convert_detections2tracklets()\" and \"deeplabcut.convert_raw_tracks_to_h5()\".\n",
            "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqaCw15v8EmB"
      },
      "source": [
        "Now you can look at the plot-poses file and check the \"plot-likelihood.png\" might want to change the \"p-cutoff\" in the config.yaml file so that you have only high confidnece points plotted in the video. i.e. ~0.8 or 0.9. The current default is 0.4. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCrUvQIvoEKD"
      },
      "source": [
        "## Create labeled video:\n",
        "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDF7Q7KoEKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a87020-4df7-4f9b-e57c-0c1f1ca271d7"
      },
      "source": [
        "deeplabcut.create_labeled_video(path_config_file,\n",
        "                                videofile_path, \n",
        "                                shuffle=shuffle, \n",
        "                                draw_skeleton=True, \n",
        "                                videotype=VideoType, \n",
        "                                save_frames=False,\n",
        "                                filtered=True, \n",
        "                                track_method = tracktype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analyzing all the videos in the directory...\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos  already exists!\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos  already exists!\n",
            "Starting to process video: /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot06-2_CUT.mp4\n",
            "Starting to process video: /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Video_Pers2_CUT.mp4\n",
            "Loading /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot06-2_CUT.mp4 and data.\n",
            "Loading /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Video_Pers2_CUT.mp4 and data.\n",
            "Labeled video already created. Skipping...\n",
            "Labeled video already created. Skipping...\n",
            "Starting to process video: /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot03-2.mp4\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos  already exists!\n",
            "Loading /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot03-2.mp4 and data.\n",
            "No filtered data file found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot03-2 and scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000 and box tracker.\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos  already exists!\n",
            "/content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos  already exists!\n",
            "Starting to process video: /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1.mp4\n",
            "Loading /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/VPers1.mp4 and data.\n",
            "Starting to process video: /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot05-2_CUT.mp4\n",
            "Loading /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos/Pilot05-2_CUT.mp4 and data.\n",
            "No filtered data file found in /content/drive/MyDrive/ColabFiles/maDLC_MM_hands2/Inference_videos for video Pilot05-2_CUT and scorer DLC_resnet50_maDLC_MM_handsJul8shuffle1_20000 and box tracker.\n",
            "Duration of video [s]: 6.87, recorded with 30.0 fps!\n",
            "Overall # of frames: 206 with cropped frame dimensions: 852 480\n",
            "Generating frames and creating video.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 206/206 [00:10<00:00, 20.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}